"""
Face Recognition System - Identification Module V2
Luá»“ng Nháº­n dáº¡ng vá»›i Database Manager (folder-based structure)

Chá»©c nÄƒng:
1. Thu tháº­p áº£nh/video cáº§n nháº­n diá»‡n
2. TrÃ­ch xuáº¥t embedding tá»« khuÃ´n máº·t chÆ°a rÃµ danh tÃ­nh
3. TÃ¬m kiáº¿m vÃ  so sÃ¡nh 1:N vá»›i database (Ä‘á»c tá»« face_database/<folder_name>/)
4. Tráº£ vá» káº¿t quáº£ trÃ¹ng khá»›p vá»›i thÃ´ng tin Ä‘áº§y Ä‘á»§
"""

import os
from datetime import datetime
from typing import Dict, List, Optional, Tuple

import cv2
import face_recognition
import numpy as np

from database_manager import DatabaseManager


class FaceIdentificationServiceV2:
    """Service quáº£n lÃ½ nháº­n dáº¡ng khuÃ´n máº·t - PhiÃªn báº£n 2"""

    def __init__(self, db_root: str = "face_database"):
        """
        Args:
            db_root: ThÆ° má»¥c gá»‘c database
        """
        self.db = DatabaseManager(db_root=db_root)

    def reload_database(self):
        """Táº£i láº¡i database (khÃ´ng cáº§n thiáº¿t vÃ¬ Ä‘á»c trá»±c tiáº¿p tá»« file)"""
        print(f"ğŸ”„ [IDENTIFICATION] Database tá»± Ä‘á»™ng cáº­p nháº­t tá»«: {self.db.db_root}")
        people = self.db.get_all_people()
        print(f"ğŸ“Š [IDENTIFICATION] Tá»•ng sá»‘ ngÆ°á»i: {len(people)}")

    def identify_face(
        self, image_path: str, max_results: int = 5, confidence_threshold: float = 0.6
    ) -> Dict:
        """
        Nháº­n dáº¡ng khuÃ´n máº·t tá»« áº£nh

        Args:
            image_path: ÄÆ°á»ng dáº«n áº£nh cáº§n nháº­n diá»‡n
            max_results: Sá»‘ lÆ°á»£ng káº¿t quáº£ tá»‘i Ä‘a tráº£ vá»
            confidence_threshold: NgÆ°á»¡ng tin cáº­y tá»‘i thiá»ƒu

        Returns:
            Dict chá»©a káº¿t quáº£ identification
        """
        result = {"success": False, "faces_detected": 0, "faces": [], "message": ""}

        try:
            # Kiá»ƒm tra database
            all_embeddings, all_metadata = self.db.get_all_embeddings_with_info()

            if not all_embeddings:
                result["message"] = "âš ï¸ Database trá»‘ng. Vui lÃ²ng Ä‘Äƒng kÃ½ khuÃ´n máº·t trÆ°á»›c!"
                return result

            # BÆ°á»›c 1: Táº£i áº£nh cáº§n nháº­n diá»‡n
            print(f"ğŸ” [IDENTIFICATION] Äang xá»­ lÃ½ áº£nh: {image_path}")
            image = face_recognition.load_image_file(image_path)

            # BÆ°á»›c 2: PhÃ¡t hiá»‡n táº¥t cáº£ khuÃ´n máº·t
            face_locations = face_recognition.face_locations(image)

            if not face_locations:
                result["message"] = "âŒ KhÃ´ng phÃ¡t hiá»‡n khuÃ´n máº·t nÃ o trong áº£nh"
                return result

            result["faces_detected"] = len(face_locations)
            print(f"ğŸ‘¤ [IDENTIFICATION] PhÃ¡t hiá»‡n {len(face_locations)} khuÃ´n máº·t")

            # BÆ°á»›c 3: TrÃ­ch xuáº¥t embeddings cho táº¥t cáº£ khuÃ´n máº·t
            face_encodings = face_recognition.face_encodings(image, face_locations)

            # BÆ°á»›c 4: TÃ¬m kiáº¿m vÃ  so sÃ¡nh 1:N vá»›i database
            for i, (face_location, face_encoding) in enumerate(zip(face_locations, face_encodings)):
                print(f"ğŸ”¬ [IDENTIFICATION] Äang tÃ¬m kiáº¿m cho khuÃ´n máº·t #{i+1}...")

                # So sÃ¡nh vá»›i database
                matches = self._search_database(
                    face_encoding,
                    all_embeddings,
                    all_metadata,
                    max_results=max_results,
                    threshold=confidence_threshold,
                )

                face_result = {
                    "face_number": i + 1,
                    "location": {
                        "top": face_location[0],
                        "right": face_location[1],
                        "bottom": face_location[2],
                        "left": face_location[3],
                    },
                    "matches": matches,
                    "best_match": matches[0] if matches else None,
                }

                result["faces"].append(face_result)

                if matches:
                    print(f"âœ… [IDENTIFICATION] TÃ¬m tháº¥y {len(matches)} káº¿t quáº£ phÃ¹ há»£p")
                    print(
                        f"   Top match: {matches[0]['user_name']} (folder: {matches[0]['folder_name']}, {matches[0]['confidence']:.1f}%)"
                    )
                else:
                    print(f"â“ [IDENTIFICATION] KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ phÃ¹ há»£p")

            result["success"] = True
            result["message"] = f"âœ… ÄÃ£ xá»­ lÃ½ {len(face_locations)} khuÃ´n máº·t"

        except Exception as e:
            result["message"] = f"âŒ Lá»—i: {str(e)}"
            print(result["message"])

        return result

    def identify_face_from_frame(
        self, frame: np.ndarray, confidence_threshold: float = 0.6
    ) -> List[Dict]:
        """
        Nháº­n dáº¡ng khuÃ´n máº·t tá»« frame (dÃ¹ng cho webcam/video)

        Args:
            frame: Frame áº£nh (numpy array)
            confidence_threshold: NgÆ°á»¡ng tin cáº­y

        Returns:
            List cÃ¡c káº¿t quáº£ nháº­n diá»‡n
        """
        results = []

        try:
            all_embeddings, all_metadata = self.db.get_all_embeddings_with_info()

            if not all_embeddings:
                return results

            # Resize frame Ä‘á»ƒ tÄƒng tá»‘c
            small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)
            rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)

            # PhÃ¡t hiá»‡n khuÃ´n máº·t
            face_locations = face_recognition.face_locations(rgb_small_frame)
            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)

            for face_location, face_encoding in zip(face_locations, face_encodings):
                # TÃ¬m kiáº¿m trong database
                matches = self._search_database(
                    face_encoding,
                    all_embeddings,
                    all_metadata,
                    max_results=1,
                    threshold=confidence_threshold,
                )

                # Scale láº¡i location vá» kÃ­ch thÆ°á»›c gá»‘c
                top, right, bottom, left = face_location
                top *= 4
                right *= 4
                bottom *= 4
                left *= 4

                result = {
                    "location": (top, right, bottom, left),
                    "match": matches[0] if matches else None,
                }

                results.append(result)

        except Exception as e:
            print(f"âŒ Lá»—i identify_face_from_frame: {e}")

        return results

    def _search_database(
        self,
        query_embedding: np.ndarray,
        all_embeddings: List[np.ndarray],
        all_metadata: List[Dict],
        max_results: int = 5,
        threshold: float = 0.6,
    ) -> List[Dict]:
        """
        TÃ¬m kiáº¿m embedding trong database (1:N search)

        Args:
            query_embedding: Embedding cáº§n tÃ¬m
            all_embeddings: List táº¥t cáº£ embeddings
            all_metadata: List táº¥t cáº£ metadata tÆ°Æ¡ng á»©ng
            max_results: Sá»‘ káº¿t quáº£ tá»‘i Ä‘a
            threshold: NgÆ°á»¡ng khoáº£ng cÃ¡ch

        Returns:
            List cÃ¡c káº¿t quáº£ match, sáº¯p xáº¿p theo Ä‘á»™ tin cáº­y
        """
        if not all_embeddings:
            return []

        # TÃ­nh khoáº£ng cÃ¡ch vá»›i táº¥t cáº£ embeddings
        distances = face_recognition.face_distance(all_embeddings, query_embedding)

        # TÃ¬m cÃ¡c káº¿t quáº£ phÃ¹ há»£p (distance < threshold)
        matches = []
        for i, distance in enumerate(distances):
            if distance < threshold:
                metadata = all_metadata[i]
                confidence = (1 - distance) * 100

                matches.append(
                    {
                        "folder_name": metadata["folder_name"],
                        "user_name": metadata["user_name"],
                        "gender": metadata.get("gender", ""),
                        "birth_year": metadata.get("birth_year", ""),
                        "hometown": metadata.get("hometown", ""),
                        "residence": metadata.get("residence", ""),
                        "confidence": float(confidence),
                        "distance": float(distance),
                        "created_at": metadata.get("created_at"),
                        "embedding_count": metadata.get("embedding_count", 0),
                    }
                )

        # Sáº¯p xáº¿p theo confidence (cao nháº¥t trÆ°á»›c)
        matches.sort(key=lambda x: x["confidence"], reverse=True)

        # Giá»›i háº¡n sá»‘ káº¿t quáº£
        return matches[:max_results]

    def identify_and_annotate_image(
        self,
        image_path: str,
        output_path: str,
        confidence_threshold: float = 0.6,
        draw_confidence: bool = True,
    ) -> Dict:
        """
        Nháº­n dáº¡ng vÃ  váº½ annotation lÃªn áº£nh

        Args:
            image_path: ÄÆ°á»ng dáº«n áº£nh input
            output_path: ÄÆ°á»ng dáº«n lÆ°u áº£nh output
            confidence_threshold: NgÆ°á»¡ng tin cáº­y
            draw_confidence: Váº½ Ä‘á»™ tin cáº­y lÃªn áº£nh

        Returns:
            Dict káº¿t quáº£
        """
        result = self.identify_face(image_path, confidence_threshold=confidence_threshold)

        if not result["success"] or not result["faces"]:
            return result

        # Load áº£nh
        image = cv2.imread(image_path)

        # Váº½ lÃªn áº£nh
        for face_data in result["faces"]:
            if face_data["best_match"]:
                match = face_data["best_match"]
                loc = face_data["location"]

                # Táº¡o info text
                info_lines = [match["user_name"]]
                if match.get("gender"):
                    info_lines.append(f"GT: {match['gender']}")
                if match.get("birth_year"):
                    info_lines.append(f"NS: {match['birth_year']}")
                if match.get("hometown"):
                    info_lines.append(f"QQ: {match['hometown']}")
                if match.get("residence"):
                    info_lines.append(f"NSS: {match['residence']}")
                if draw_confidence:
                    info_lines.append(f"{match['confidence']:.1f}%")

                # Váº½ rectangle
                cv2.rectangle(
                    image, (loc["left"], loc["top"]), (loc["right"], loc["bottom"]), (0, 255, 0), 2
                )

                # Váº½ info
                y_offset = loc["top"] - 10
                for line in reversed(info_lines):
                    cv2.putText(
                        image,
                        line,
                        (loc["left"], y_offset),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (0, 255, 0),
                        2,
                    )
                    y_offset -= 25

        # LÆ°u áº£nh
        cv2.imwrite(output_path, image)
        result["output_path"] = output_path

        return result

    def batch_identify(
        self, image_paths: List[str], confidence_threshold: float = 0.6
    ) -> List[Dict]:
        """
        Nháº­n dáº¡ng hÃ ng loáº¡t

        Args:
            image_paths: List Ä‘Æ°á»ng dáº«n áº£nh
            confidence_threshold: NgÆ°á»¡ng tin cáº­y

        Returns:
            List káº¿t quáº£
        """
        results = []

        for image_path in image_paths:
            result = self.identify_face(image_path, confidence_threshold=confidence_threshold)
            results.append(result)

        return results


# Testing
if __name__ == "__main__":
    print("=" * 70)
    print("TEST IDENTIFICATION SERVICE V2 - FOLDER STRUCTURE")
    print("=" * 70)

    identification = FaceIdentificationServiceV2()

    # Test vá»›i áº£nh cÃ³ sáºµn
    test_images = []
    if os.path.exists("faces"):
        for person_folder in os.listdir("faces"):
            person_path = os.path.join("faces", person_folder)
            if os.path.isdir(person_path):
                for img_file in os.listdir(person_path):
                    if img_file.lower().endswith((".jpg", ".jpeg", ".png")):
                        test_images.append(os.path.join(person_path, img_file))
                        break

    if test_images:
        test_img = test_images[0]
        print(f"\nğŸ” Test nháº­n diá»‡n: {test_img}\n")

        result = identification.identify_face(image_path=test_img, confidence_threshold=0.6)

        if result["success"] and result["faces"]:
            for face_data in result["faces"]:
                if face_data["best_match"]:
                    match = face_data["best_match"]
                    print(f"\nâœ… Nháº­n diá»‡n thÃ nh cÃ´ng!")
                    print(f"   ğŸ‘¤ TÃªn: {match['user_name']}")
                    print(f"   ğŸ“ Folder: {match['folder_name']}")
                    print(f"   ğŸ¯ Äá»™ tin cáº­y: {match['confidence']:.1f}%")

                    if match.get("gender"):
                        print(f"   âš¥ Giá»›i tÃ­nh: {match['gender']}")
                    if match.get("birth_year"):
                        print(f"   ğŸ‚ NÄƒm sinh: {match['birth_year']}")
                    if match.get("hometown"):
                        print(f"   ğŸ¡ QuÃª quÃ¡n: {match['hometown']}")
                    if match.get("residence"):
                        print(f"   ğŸ“ NÆ¡i sinh sá»‘ng: {match['residence']}")
        else:
            print(f"\n{result['message']}")
    else:
        print("\nâš ï¸ KhÃ´ng tÃ¬m tháº¥y áº£nh test")

    print("\nâœ… TEST HOÃ€N Táº¤T")
