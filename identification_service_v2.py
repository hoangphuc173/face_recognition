"""
Face Recognition System - Identification Module V2
Lu·ªìng Nh·∫≠n d·∫°ng v·ªõi Database Manager (folder-based structure)

Ch·ª©c nƒÉng:
1. Thu th·∫≠p ·∫£nh/video c·∫ßn nh·∫≠n di·ªán
2. Tr√≠ch xu·∫•t embedding t·ª´ khu√¥n m·∫∑t ch∆∞a r√µ danh t√≠nh
3. T√¨m ki·∫øm v√† so s√°nh 1:N v·ªõi database (ƒë·ªçc t·ª´ face_database/<folder_name>/)
4. Tr·∫£ v·ªÅ k·∫øt qu·∫£ tr√πng kh·ªõp v·ªõi th√¥ng tin ƒë·∫ßy ƒë·ªß
"""

import face_recognition
import numpy as np
import cv2
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import os

from database_manager import DatabaseManager

class FaceIdentificationServiceV2:
    """Service qu·∫£n l√Ω nh·∫≠n d·∫°ng khu√¥n m·∫∑t - Phi√™n b·∫£n 2"""
    
    def __init__(self, db_root: str = "face_database"):
        """
        Args:
            db_root: Th∆∞ m·ª•c g·ªëc database
        """
        self.db = DatabaseManager(db_root=db_root)
    
    def reload_database(self):
        """T·∫£i l·∫°i database (kh√¥ng c·∫ßn thi·∫øt v√¨ ƒë·ªçc tr·ª±c ti·∫øp t·ª´ file)"""
        print(f"üîÑ [IDENTIFICATION] Database t·ª± ƒë·ªông c·∫≠p nh·∫≠t t·ª´: {self.db.db_root}")
        people = self.db.get_all_people()
        print(f"üìä [IDENTIFICATION] T·ªïng s·ªë ng∆∞·ªùi: {len(people)}")
    
    def identify_face(
        self, 
        image_path: str, 
        max_results: int = 5,
        confidence_threshold: float = 0.6
    ) -> Dict:
        """
        Nh·∫≠n d·∫°ng khu√¥n m·∫∑t t·ª´ ·∫£nh
        
        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ·∫£nh c·∫ßn nh·∫≠n di·ªán
            max_results: S·ªë l∆∞·ª£ng k·∫øt qu·∫£ t·ªëi ƒëa tr·∫£ v·ªÅ
            confidence_threshold: Ng∆∞·ª°ng tin c·∫≠y t·ªëi thi·ªÉu
            
        Returns:
            Dict ch·ª©a k·∫øt qu·∫£ identification
        """
        result = {
            "success": False,
            "faces_detected": 0,
            "faces": [],
            "message": ""
        }
        
        try:
            # Ki·ªÉm tra database
            all_embeddings, all_metadata = self.db.get_all_embeddings_with_info()
            
            if not all_embeddings:
                result["message"] = "‚ö†Ô∏è Database tr·ªëng. Vui l√≤ng ƒëƒÉng k√Ω khu√¥n m·∫∑t tr∆∞·ªõc!"
                return result
            
            # B∆∞·ªõc 1: T·∫£i ·∫£nh c·∫ßn nh·∫≠n di·ªán
            print(f"üîç [IDENTIFICATION] ƒêang x·ª≠ l√Ω ·∫£nh: {image_path}")
            image = face_recognition.load_image_file(image_path)
            
            # B∆∞·ªõc 2: Ph√°t hi·ªán t·∫•t c·∫£ khu√¥n m·∫∑t
            face_locations = face_recognition.face_locations(image)
            
            if not face_locations:
                result["message"] = "‚ùå Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t n√†o trong ·∫£nh"
                return result
            
            result["faces_detected"] = len(face_locations)
            print(f"üë§ [IDENTIFICATION] Ph√°t hi·ªán {len(face_locations)} khu√¥n m·∫∑t")
            
            # B∆∞·ªõc 3: Tr√≠ch xu·∫•t embeddings cho t·∫•t c·∫£ khu√¥n m·∫∑t
            face_encodings = face_recognition.face_encodings(image, face_locations)
            
            # B∆∞·ªõc 4: T√¨m ki·∫øm v√† so s√°nh 1:N v·ªõi database
            for i, (face_location, face_encoding) in enumerate(zip(face_locations, face_encodings)):
                print(f"üî¨ [IDENTIFICATION] ƒêang t√¨m ki·∫øm cho khu√¥n m·∫∑t #{i+1}...")
                
                # So s√°nh v·ªõi database
                matches = self._search_database(
                    face_encoding,
                    all_embeddings,
                    all_metadata,
                    max_results=max_results,
                    threshold=confidence_threshold
                )
                
                face_result = {
                    "face_number": i + 1,
                    "location": {
                        "top": face_location[0],
                        "right": face_location[1],
                        "bottom": face_location[2],
                        "left": face_location[3]
                    },
                    "matches": matches,
                    "best_match": matches[0] if matches else None
                }
                
                result["faces"].append(face_result)
                
                if matches:
                    print(f"‚úÖ [IDENTIFICATION] T√¨m th·∫•y {len(matches)} k·∫øt qu·∫£ ph√π h·ª£p")
                    print(f"   Top match: {matches[0]['user_name']} (folder: {matches[0]['folder_name']}, {matches[0]['confidence']:.1f}%)")
                else:
                    print(f"‚ùì [IDENTIFICATION] Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ ph√π h·ª£p")
            
            result["success"] = True
            result["message"] = f"‚úÖ ƒê√£ x·ª≠ l√Ω {len(face_locations)} khu√¥n m·∫∑t"
            
        except Exception as e:
            result["message"] = f"‚ùå L·ªói: {str(e)}"
            print(result["message"])
        
        return result
    
    def identify_face_from_frame(
        self, 
        frame: np.ndarray,
        confidence_threshold: float = 0.6
    ) -> List[Dict]:
        """
        Nh·∫≠n d·∫°ng khu√¥n m·∫∑t t·ª´ frame (d√πng cho webcam/video)
        
        Args:
            frame: Frame ·∫£nh (numpy array)
            confidence_threshold: Ng∆∞·ª°ng tin c·∫≠y
            
        Returns:
            List c√°c k·∫øt qu·∫£ nh·∫≠n di·ªán
        """
        results = []
        
        try:
            all_embeddings, all_metadata = self.db.get_all_embeddings_with_info()
            
            if not all_embeddings:
                return results
            
            # Resize frame ƒë·ªÉ tƒÉng t·ªëc
            small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)
            rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
            
            # Ph√°t hi·ªán khu√¥n m·∫∑t
            face_locations = face_recognition.face_locations(rgb_small_frame)
            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)
            
            for face_location, face_encoding in zip(face_locations, face_encodings):
                # T√¨m ki·∫øm trong database
                matches = self._search_database(
                    face_encoding,
                    all_embeddings,
                    all_metadata,
                    max_results=1,
                    threshold=confidence_threshold
                )
                
                # Scale l·∫°i location v·ªÅ k√≠ch th∆∞·ªõc g·ªëc
                top, right, bottom, left = face_location
                top *= 4
                right *= 4
                bottom *= 4
                left *= 4
                
                result = {
                    "location": (top, right, bottom, left),
                    "match": matches[0] if matches else None
                }
                
                results.append(result)
        
        except Exception as e:
            print(f"‚ùå L·ªói identify_face_from_frame: {e}")
        
        return results
    
    def _search_database(
        self,
        query_embedding: np.ndarray,
        all_embeddings: List[np.ndarray],
        all_metadata: List[Dict],
        max_results: int = 5,
        threshold: float = 0.6
    ) -> List[Dict]:
        """
        T√¨m ki·∫øm embedding trong database (1:N search)
        
        Args:
            query_embedding: Embedding c·∫ßn t√¨m
            all_embeddings: List t·∫•t c·∫£ embeddings
            all_metadata: List t·∫•t c·∫£ metadata t∆∞∆°ng ·ª©ng
            max_results: S·ªë k·∫øt qu·∫£ t·ªëi ƒëa
            threshold: Ng∆∞·ª°ng kho·∫£ng c√°ch
            
        Returns:
            List c√°c k·∫øt qu·∫£ match, s·∫Øp x·∫øp theo ƒë·ªô tin c·∫≠y
        """
        if not all_embeddings:
            return []
        
        # T√≠nh kho·∫£ng c√°ch v·ªõi t·∫•t c·∫£ embeddings
        distances = face_recognition.face_distance(all_embeddings, query_embedding)
        
        # T√¨m c√°c k·∫øt qu·∫£ ph√π h·ª£p (distance < threshold)
        matches = []
        for i, distance in enumerate(distances):
            if distance < threshold:
                metadata = all_metadata[i]
                confidence = (1 - distance) * 100
                
                matches.append({
                    "folder_name": metadata["folder_name"],
                    "user_name": metadata["user_name"],
                    "gender": metadata.get("gender", ""),
                    "birth_year": metadata.get("birth_year", ""),
                    "hometown": metadata.get("hometown", ""),
                    "residence": metadata.get("residence", ""),
                    "confidence": float(confidence),
                    "distance": float(distance),
                    "created_at": metadata.get("created_at"),
                    "embedding_count": metadata.get("embedding_count", 0)
                })
        
        # S·∫Øp x·∫øp theo confidence (cao nh·∫•t tr∆∞·ªõc)
        matches.sort(key=lambda x: x["confidence"], reverse=True)
        
        # Gi·ªõi h·∫°n s·ªë k·∫øt qu·∫£
        return matches[:max_results]
    
    def identify_and_annotate_image(
        self,
        image_path: str,
        output_path: str,
        confidence_threshold: float = 0.6,
        draw_confidence: bool = True
    ) -> Dict:
        """
        Nh·∫≠n d·∫°ng v√† v·∫Ω annotation l√™n ·∫£nh
        
        Args:
            image_path: ƒê∆∞·ªùng d·∫´n ·∫£nh input
            output_path: ƒê∆∞·ªùng d·∫´n l∆∞u ·∫£nh output
            confidence_threshold: Ng∆∞·ª°ng tin c·∫≠y
            draw_confidence: V·∫Ω ƒë·ªô tin c·∫≠y l√™n ·∫£nh
            
        Returns:
            Dict k·∫øt qu·∫£
        """
        result = self.identify_face(image_path, confidence_threshold=confidence_threshold)
        
        if not result["success"] or not result["faces"]:
            return result
        
        # Load ·∫£nh
        image = cv2.imread(image_path)
        
        # V·∫Ω l√™n ·∫£nh
        for face_data in result["faces"]:
            if face_data["best_match"]:
                match = face_data["best_match"]
                loc = face_data["location"]
                
                # T·∫°o info text
                info_lines = [match["user_name"]]
                if match.get("gender"):
                    info_lines.append(f"GT: {match['gender']}")
                if match.get("birth_year"):
                    info_lines.append(f"NS: {match['birth_year']}")
                if match.get("hometown"):
                    info_lines.append(f"QQ: {match['hometown']}")
                if match.get("residence"):
                    info_lines.append(f"NSS: {match['residence']}")
                if draw_confidence:
                    info_lines.append(f"{match['confidence']:.1f}%")
                
                # V·∫Ω rectangle
                cv2.rectangle(image, (loc["left"], loc["top"]), 
                            (loc["right"], loc["bottom"]), (0, 255, 0), 2)
                
                # V·∫Ω info
                y_offset = loc["top"] - 10
                for line in reversed(info_lines):
                    cv2.putText(image, line, (loc["left"], y_offset),
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                    y_offset -= 25
        
        # L∆∞u ·∫£nh
        cv2.imwrite(output_path, image)
        result["output_path"] = output_path
        
        return result
    
    def batch_identify(
        self,
        image_paths: List[str],
        confidence_threshold: float = 0.6
    ) -> List[Dict]:
        """
        Nh·∫≠n d·∫°ng h√†ng lo·∫°t
        
        Args:
            image_paths: List ƒë∆∞·ªùng d·∫´n ·∫£nh
            confidence_threshold: Ng∆∞·ª°ng tin c·∫≠y
            
        Returns:
            List k·∫øt qu·∫£
        """
        results = []
        
        for image_path in image_paths:
            result = self.identify_face(image_path, confidence_threshold=confidence_threshold)
            results.append(result)
        
        return results


# Testing
if __name__ == "__main__":
    print("=" * 70)
    print("TEST IDENTIFICATION SERVICE V2 - FOLDER STRUCTURE")
    print("=" * 70)
    
    identification = FaceIdentificationServiceV2()
    
    # Test v·ªõi ·∫£nh c√≥ s·∫µn
    test_images = []
    if os.path.exists("faces"):
        for person_folder in os.listdir("faces"):
            person_path = os.path.join("faces", person_folder)
            if os.path.isdir(person_path):
                for img_file in os.listdir(person_path):
                    if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                        test_images.append(os.path.join(person_path, img_file))
                        break
    
    if test_images:
        test_img = test_images[0]
        print(f"\nüîç Test nh·∫≠n di·ªán: {test_img}\n")
        
        result = identification.identify_face(
            image_path=test_img,
            confidence_threshold=0.6
        )
        
        if result["success"] and result["faces"]:
            for face_data in result["faces"]:
                if face_data["best_match"]:
                    match = face_data["best_match"]
                    print(f"\n‚úÖ Nh·∫≠n di·ªán th√†nh c√¥ng!")
                    print(f"   üë§ T√™n: {match['user_name']}")
                    print(f"   üìÅ Folder: {match['folder_name']}")
                    print(f"   üéØ ƒê·ªô tin c·∫≠y: {match['confidence']:.1f}%")
                    
                    if match.get('gender'):
                        print(f"   ‚ö• Gi·ªõi t√≠nh: {match['gender']}")
                    if match.get('birth_year'):
                        print(f"   üéÇ NƒÉm sinh: {match['birth_year']}")
                    if match.get('hometown'):
                        print(f"   üè° Qu√™ qu√°n: {match['hometown']}")
                    if match.get('residence'):
                        print(f"   üìç N∆°i sinh s·ªëng: {match['residence']}")
        else:
            print(f"\n{result['message']}")
    else:
        print("\n‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ·∫£nh test")
    
    print("\n‚úÖ TEST HO√ÄN T·∫§T")
